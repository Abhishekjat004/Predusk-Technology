# Predusk-Technology

# ğŸ“˜ AI-Powered Document Q&A System

## ğŸš€ Overview
This project is a **Document Question-Answering System** built with **Flask**, **Google Gemini**, **Cohere**, and **Pinecone**.  
Users can upload **PDFs or raw text**, which are split into chunks, embedded using **Google Generative AI embeddings**, and stored in **Pinecone**.  
When a user asks a question:
1. The query is rewritten into a standalone form (via Gemini).
2. Relevant chunks are retrieved from Pinecone.
3. Cohere reranks results for accuracy.
4. Gemini generates the final context-based answer.

---

## ğŸ—ï¸ Architecture
![Architecture Diagram](./architecture.png) <!-- Add your diagram -->

**Workflow:**
1. **Upload PDF/Text** â†’ Process & Chunk â†’ Store in Pinecone  
2. **Ask Question** â†’ Query Rewriter (Gemini)  
3. **Retriever** (Pinecone + Gemini embeddings)  
4. **Reranker** (Cohere)  
5. **Answer Generator** (Gemini with context)  

---

## âš™ï¸ Configuration

### ğŸ”‘ Environment Variables
Create a `.env` file in the project root (see `.env.example`):

```env
COHERE_API_KEY=your_cohere_api_key
GEMINI_API_KEY=your_google_gemini_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=your_pinecone_index_name
ğŸ“‘ Chunking Parameters
chunk_size: 1000

chunk_overlap: 150

ğŸ” Retriever / Reranker
Retriever: Pinecone Vector DB (Google Generative AI embeddings)

Reranker: Cohere Rerank v3.0

ğŸŒ Providers Used
Google Generative AI (Embeddings + Gemini Model)

Cohere API (Reranking)

Pinecone (Vector Database)

Flask (Backend Framework)

âš¡ Quick Start
1. Clone the repo
bash
Copy code
git clone https://github.com/yourusername/yourproject.git
cd yourproject
2. Install dependencies
bash
Copy code
pip install -r requirements.txt
3. Setup environment
bash
Copy code
cp .env.example .env
# fill in your API keys
4. Run locally
bash
Copy code
python app.py
App will run at: http://localhost:5000

ğŸŒ Deployment
This project is deployed on Railway.
ğŸ”— Live App: https://yourapp.railway.app

ğŸ“ Remarks
âš ï¸ Free tier limits on Gemini & Cohere may restrict requests.

âš ï¸ Pinecone free index has size & query limits.

ğŸš€ Improvements to consider:

Add authentication & user accounts.

Store chat history in a database (not just memory).

Extend support for DOCX/TXT uploads.

Frontend improvements.

ğŸ“œ License
MIT License

yaml
Copy code

---

Would you like me to also generate the **`.env.example` file** and a **requirements.txt** for your project (so setup is suexample`).

```env
API_KEY=your_api_key_here
MODEL_PROVIDER=openai
DB_URL=your_database_url

